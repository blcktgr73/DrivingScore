#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 4-D Step 1: Class Weight ì ìš©
====================================

Phase 4-Cì˜ Logistic Regressionì— Class Weightë¥¼ ì ìš©í•˜ì—¬
Class Imbalance ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

ëª©í‘œ:
- Recall: 6.2% â†’ 25%
- Precision: 73.9% â†’ 60%
- F1: 11.4% â†’ 35%

ì‘ì„±ì¼: 2025-10-10
"""

import os
import sys
import json
import random
import math
from datetime import datetime, timedelta
from collections import defaultdict, Counter

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

print("=" * 80)
print(" Phase 4-D Step 1: Class Weight ì ìš©")
print("=" * 80)
print()

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Phase 4-Cì—ì„œ ê°€ì ¸ì˜´)
# ============================================================================

def mean(data):
    return sum(data) / len(data) if data else 0

def std(data):
    if not data:
        return 0
    m = mean(data)
    variance = sum((x - m) ** 2 for x in data) / len(data)
    return math.sqrt(variance)

def normal_random(mean_val, std_val):
    """ë°•ìŠ¤-ë®¬ëŸ¬ ë³€í™˜"""
    u1 = random.random()
    u2 = random.random()
    z = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)
    return mean_val + z * std_val

def correlation(x, y):
    """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜"""
    if len(x) != len(y) or len(x) == 0:
        return 0
    n = len(x)
    mean_x = mean(x)
    mean_y = mean(y)
    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
    denominator = math.sqrt(sum((x[i] - mean_x)**2 for i in range(n)) *
                           sum((y[i] - mean_y)**2 for i in range(n)))
    return numerator / denominator if denominator != 0 else 0

def calculate_distance_km(lat1, lon1, lat2, lon2):
    """ê±°ë¦¬ ê³„ì‚° (km)"""
    R = 6371
    lat1_rad = math.radians(lat1)
    lat2_rad = math.radians(lat2)
    delta_lat = math.radians(lat2 - lat1)
    delta_lon = math.radians(lon2 - lon1)
    a = (math.sin(delta_lat / 2) ** 2 +
         math.cos(lat1_rad) * math.cos(lat2_rad) *
         math.sin(delta_lon / 2) ** 2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return R * c

# ============================================================================
# ê°œì„ ëœ Logistic Regression (Class Weight ì ìš©)
# ============================================================================

class LogisticRegressionWithClassWeight:
    """Class Weightë¥¼ ì ìš©í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€"""
    def __init__(self, learning_rate=0.01, iterations=1000, class_weight='balanced'):
        self.lr = learning_rate
        self.iterations = iterations
        self.class_weight = class_weight
        self.weights = None
        self.bias = None
        self.weight_positive = 1.0
        self.weight_negative = 1.0

    def sigmoid(self, z):
        return 1 / (1 + math.exp(-min(max(z, -500), 500)))

    def fit(self, X, y):
        n_samples, n_features = len(X), len(X[0])
        self.weights = [0.0] * n_features
        self.bias = 0.0

        # Class weight ê³„ì‚°
        if self.class_weight == 'balanced':
            n_positive = sum(y)
            n_negative = n_samples - n_positive

            # Balanced weight: n_samples / (n_classes * n_samples_for_class)
            self.weight_positive = n_samples / (2 * n_positive)
            self.weight_negative = n_samples / (2 * n_negative)

            print(f"\n[Class Weight ì ìš©]")
            print(f"  ì‚¬ê³  ìƒ˜í”Œ: {n_positive}ê°œ (ê°€ì¤‘ì¹˜: {self.weight_positive:.4f})")
            print(f"  ë¹„ì‚¬ê³  ìƒ˜í”Œ: {n_negative}ê°œ (ê°€ì¤‘ì¹˜: {self.weight_negative:.4f})")
            print(f"  â†’ ì‚¬ê³  ìƒ˜í”Œì— {self.weight_positive/self.weight_negative:.2f}ë°° ê°€ì¤‘ì¹˜ ë¶€ì—¬")

        for iteration in range(self.iterations):
            # Forward pass
            predictions = []
            for i in range(n_samples):
                z = sum(X[i][j] * self.weights[j] for j in range(n_features)) + self.bias
                predictions.append(self.sigmoid(z))

            # Compute gradients with class weights
            dw = [0.0] * n_features
            db = 0.0
            for i in range(n_samples):
                error = predictions[i] - y[i]

                # Class weight ì ìš©
                weight = self.weight_positive if y[i] == 1 else self.weight_negative

                for j in range(n_features):
                    dw[j] += weight * error * X[i][j]
                db += weight * error

            # Update weights
            for j in range(n_features):
                self.weights[j] -= self.lr * dw[j] / n_samples
            self.bias -= self.lr * db / n_samples

            # Progress
            if (iteration + 1) % 200 == 0:
                print(f"  Iteration {iteration + 1}/{self.iterations} ì™„ë£Œ")

    def predict_proba(self, X):
        predictions = []
        for i in range(len(X)):
            z = sum(X[i][j] * self.weights[j] for j in range(len(self.weights))) + self.bias
            predictions.append(self.sigmoid(z))
        return predictions

    def predict(self, X, threshold=0.5):
        probas = self.predict_proba(X)
        return [1 if p >= threshold else 0 for p in probas]

# ============================================================================
# ê¸°ì¡´ Logistic Regression (Phase 4-C)
# ============================================================================

class LogisticRegression:
    """ê¸°ì¡´ ë¡œì§€ìŠ¤í‹± íšŒê·€ (ë¹„êµìš©)"""
    def __init__(self, learning_rate=0.01, iterations=1000):
        self.lr = learning_rate
        self.iterations = iterations
        self.weights = None
        self.bias = None

    def sigmoid(self, z):
        return 1 / (1 + math.exp(-min(max(z, -500), 500)))

    def fit(self, X, y):
        n_samples, n_features = len(X), len(X[0])
        self.weights = [0.0] * n_features
        self.bias = 0.0

        for iteration in range(self.iterations):
            predictions = []
            for i in range(n_samples):
                z = sum(X[i][j] * self.weights[j] for j in range(n_features)) + self.bias
                predictions.append(self.sigmoid(z))

            dw = [0.0] * n_features
            db = 0.0
            for i in range(n_samples):
                error = predictions[i] - y[i]
                for j in range(n_features):
                    dw[j] += error * X[i][j]
                db += error

            for j in range(n_features):
                self.weights[j] -= self.lr * dw[j] / n_samples
            self.bias -= self.lr * db / n_samples

            if (iteration + 1) % 200 == 0:
                print(f"  Iteration {iteration + 1}/{self.iterations} ì™„ë£Œ")

    def predict_proba(self, X):
        predictions = []
        for i in range(len(X)):
            z = sum(X[i][j] * self.weights[j] for j in range(len(self.weights))) + self.bias
            predictions.append(self.sigmoid(z))
        return predictions

    def predict(self, X, threshold=0.5):
        probas = self.predict_proba(X)
        return [1 if p >= threshold else 0 for p in probas]

# ============================================================================
# í‰ê°€ ë©”íŠ¸ë¦­
# ============================================================================

def calculate_metrics(y_true, y_pred, y_proba):
    """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    # Confusion matrix
    tp = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 1)
    fp = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 1)
    tn = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 0)
    fn = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 0)

    # Metrics
    accuracy = (tp + tn) / len(y_true) if len(y_true) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    # AUC (ê°„ë‹¨í•œ ì‚¬ë‹¤ë¦¬ê¼´ ê·¼ì‚¬)
    sorted_pairs = sorted(zip(y_proba, y_true), reverse=True)
    positives = sum(y_true)
    negatives = len(y_true) - positives

    if positives == 0 or negatives == 0:
        auc = 0.5
    else:
        true_positive = 0
        false_positive = 0
        auc_sum = 0.0
        prev_fpr = 0.0

        for prob, label in sorted_pairs:
            if label == 1:
                true_positive += 1
            else:
                false_positive += 1
                tpr = true_positive / positives
                fpr = false_positive / negatives
                auc_sum += (fpr - prev_fpr) * tpr
                prev_fpr = fpr

        auc = auc_sum

    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "auc": auc,
        "confusion_matrix": {"tp": tp, "fp": fp, "tn": tn, "fn": fn}
    }

# ============================================================================
# ë°ì´í„° ìƒì„± (Phase 4-Cì™€ ë™ì¼)
# ============================================================================

def generate_data(n_samples=15000, accident_rate=0.359):
    """
    Phase 4-Cì™€ ë™ì¼í•œ ë°ì´í„° ìƒì„±
    (ì¬í˜„ì„±ì„ ìœ„í•´ ê°„ì†Œí™”ëœ ë²„ì „)
    """
    print("\n" + "=" * 80)
    print("ğŸ“Š ë°ì´í„° ìƒì„± (Phase 4-C ê¸°ì¤€)")
    print("=" * 80)

    random.seed(42)  # ì¬í˜„ì„±

    X = []
    y = []

    for i in range(n_samples):
        # ì‚¬ê³  ì—¬ë¶€ ê²°ì •
        is_accident = 1 if random.random() < accident_rate else 0

        # ì‚¬ê³ ì¸ ê²½ìš° ì´ë²¤íŠ¸ê°€ ë” ë§ìŒ
        if is_accident:
            rapid_accel = max(0, int(normal_random(5.0, 2.0)))
            sudden_stop = max(0, int(normal_random(6.0, 2.5)))
            sharp_turn = max(0, int(normal_random(4.0, 2.0)))
            over_speed = max(0, int(normal_random(4.5, 2.0)))
        else:
            rapid_accel = max(0, int(normal_random(2.0, 1.5)))
            sudden_stop = max(0, int(normal_random(2.5, 1.5)))
            sharp_turn = max(0, int(normal_random(1.5, 1.0)))
            over_speed = max(0, int(normal_random(2.0, 1.5)))

        X.append([rapid_accel, sudden_stop, sharp_turn, over_speed])
        y.append(is_accident)

    print(f"\nì´ ìƒ˜í”Œ: {n_samples:,}ê°œ")
    print(f"ì‚¬ê³ : {sum(y):,}ê°œ ({sum(y)/len(y)*100:.1f}%)")
    print(f"ë¹„ì‚¬ê³ : {len(y)-sum(y):,}ê°œ ({(len(y)-sum(y))/len(y)*100:.1f}%)")

    return X, y

def train_test_split(X, y, test_size=0.25):
    """Train/Test ë¶„í• """
    random.seed(42)
    indices = list(range(len(X)))
    random.shuffle(indices)

    split_idx = int(len(X) * (1 - test_size))
    train_indices = indices[:split_idx]
    test_indices = indices[split_idx:]

    X_train = [X[i] for i in train_indices]
    y_train = [y[i] for i in train_indices]
    X_test = [X[i] for i in test_indices]
    y_test = [y[i] for i in test_indices]

    return X_train, X_test, y_train, y_test

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    # 1. ë°ì´í„° ìƒì„±
    X, y = generate_data(n_samples=15000, accident_rate=0.359)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

    print(f"\nTrain: {len(X_train):,}ê°œ, Test: {len(X_test):,}ê°œ")

    results = {}

    # 2. Phase 4-C ëª¨ë¸ (ê¸°ì¡´ - ë¹„êµìš©)
    print("\n" + "=" * 80)
    print("ğŸ”„ Phase 4-C: ê¸°ì¡´ Logistic Regression (Class Weight ì—†ìŒ)")
    print("=" * 80)

    model_baseline = LogisticRegression(learning_rate=0.01, iterations=500)
    model_baseline.fit(X_train, y_train)

    y_proba_baseline = model_baseline.predict_proba(X_test)
    y_pred_baseline = model_baseline.predict(X_test, threshold=0.5)

    metrics_baseline = calculate_metrics(y_test, y_pred_baseline, y_proba_baseline)

    print("\n[Phase 4-C ê²°ê³¼]")
    print(f"  Accuracy:  {metrics_baseline['accuracy']:.4f}")
    print(f"  Precision: {metrics_baseline['precision']:.4f}")
    print(f"  Recall:    {metrics_baseline['recall']:.4f}")
    print(f"  F1 Score:  {metrics_baseline['f1']:.4f}")
    print(f"  AUC:       {metrics_baseline['auc']:.4f}")
    print(f"\n  Confusion Matrix:")
    cm = metrics_baseline['confusion_matrix']
    print(f"    TP: {cm['tp']}, FP: {cm['fp']}")
    print(f"    FN: {cm['fn']}, TN: {cm['tn']}")

    results['phase4c_baseline'] = metrics_baseline

    # 3. Phase 4-D Step 1: Class Weight ì ìš©
    print("\n" + "=" * 80)
    print("âœ¨ Phase 4-D Step 1: Class Weight ì ìš©")
    print("=" * 80)

    model_weighted = LogisticRegressionWithClassWeight(
        learning_rate=0.01,
        iterations=500,
        class_weight='balanced'
    )
    model_weighted.fit(X_train, y_train)

    y_proba_weighted = model_weighted.predict_proba(X_test)
    y_pred_weighted = model_weighted.predict(X_test, threshold=0.5)

    metrics_weighted = calculate_metrics(y_test, y_pred_weighted, y_proba_weighted)

    print("\n[Phase 4-D Step 1 ê²°ê³¼]")
    print(f"  Accuracy:  {metrics_weighted['accuracy']:.4f}")
    print(f"  Precision: {metrics_weighted['precision']:.4f} (4-C: {metrics_baseline['precision']:.4f})")
    print(f"  Recall:    {metrics_weighted['recall']:.4f} (4-C: {metrics_baseline['recall']:.4f})")
    print(f"  F1 Score:  {metrics_weighted['f1']:.4f} (4-C: {metrics_baseline['f1']:.4f})")
    print(f"  AUC:       {metrics_weighted['auc']:.4f} (4-C: {metrics_baseline['auc']:.4f})")
    print(f"\n  Confusion Matrix:")
    cm_w = metrics_weighted['confusion_matrix']
    print(f"    TP: {cm_w['tp']}, FP: {cm_w['fp']}")
    print(f"    FN: {cm_w['fn']}, TN: {cm_w['tn']}")

    results['phase4d_step1_class_weight'] = metrics_weighted

    # 4. ê°œì„  ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ê°œì„  ë¶„ì„")
    print("=" * 80)

    recall_improvement = (metrics_weighted['recall'] - metrics_baseline['recall']) / metrics_baseline['recall'] * 100
    f1_improvement = (metrics_weighted['f1'] - metrics_baseline['f1']) / metrics_baseline['f1'] * 100
    precision_change = (metrics_weighted['precision'] - metrics_baseline['precision']) / metrics_baseline['precision'] * 100

    print(f"\nRecall ê°œì„ :")
    print(f"  {metrics_baseline['recall']:.1%} â†’ {metrics_weighted['recall']:.1%}")
    print(f"  +{recall_improvement:.1f}% í–¥ìƒ")

    print(f"\nF1 Score ê°œì„ :")
    print(f"  {metrics_baseline['f1']:.4f} â†’ {metrics_weighted['f1']:.4f}")
    print(f"  +{f1_improvement:.1f}% í–¥ìƒ")

    print(f"\nPrecision ë³€í™” (Trade-off):")
    print(f"  {metrics_baseline['precision']:.1%} â†’ {metrics_weighted['precision']:.1%}")
    if precision_change < 0:
        print(f"  {precision_change:.1f}% í•˜ë½ (ì˜ˆìƒëœ Trade-off)")
    else:
        print(f"  +{precision_change:.1f}% í–¥ìƒ")

    print(f"\nAUC ë³€í™”:")
    print(f"  {metrics_baseline['auc']:.4f} â†’ {metrics_weighted['auc']:.4f}")
    print(f"  {'+' if metrics_weighted['auc'] >= metrics_baseline['auc'] else ''}{(metrics_weighted['auc'] - metrics_baseline['auc']):.4f}")

    # 5. ê²°ê³¼ ì €ì¥
    results['improvements'] = {
        'recall_improvement_pct': recall_improvement,
        'f1_improvement_pct': f1_improvement,
        'precision_change_pct': precision_change,
        'auc_change': metrics_weighted['auc'] - metrics_baseline['auc']
    }

    results['summary'] = {
        'goal_recall': 0.25,
        'achieved_recall': metrics_weighted['recall'],
        'goal_f1': 0.35,
        'achieved_f1': metrics_weighted['f1'],
        'goal_precision': 0.60,
        'achieved_precision': metrics_weighted['precision']
    }

    output_file = os.path.join(os.path.dirname(__file__), 'phase4d_step1_results.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\nê²°ê³¼ ì €ì¥: {output_file}")

    # 6. ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    print("\n" + "=" * 80)
    print("ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€")
    print("=" * 80)

    goals = [
        ("Recall â‰¥ 25%", metrics_weighted['recall'] >= 0.25, f"{metrics_weighted['recall']:.1%}"),
        ("F1 Score â‰¥ 0.35", metrics_weighted['f1'] >= 0.35, f"{metrics_weighted['f1']:.4f}"),
        ("Precision â‰¥ 60%", metrics_weighted['precision'] >= 0.60, f"{metrics_weighted['precision']:.1%}"),
    ]

    for goal, achieved, value in goals:
        status = "âœ…" if achieved else "âŒ"
        print(f"  {status} {goal}: {value}")

    print("\n" + "=" * 80)
    print("âœ… Phase 4-D Step 1 ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
