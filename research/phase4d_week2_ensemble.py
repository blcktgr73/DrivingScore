#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 4-D Week 2: sklearn Ensemble ëª¨ë¸
========================================

Week 1ì˜ Class Weight + Threshold ìµœì í™”ë¥¼ ë„˜ì–´,
sklearn ê¸°ë°˜ ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸(LogisticRegression, RandomForest, GradientBoosting)ê³¼
SMOTEë¥¼ ì ìš©í•˜ì—¬ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒì„ ëª©í‘œí•©ë‹ˆë‹¤.

ì‘ì„±ì¼: 2025-10-10
"""

import os
import sys
import json
import random
import math

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

print("=" * 80)
print(" Phase 4-D Week 2: sklearn Ensemble ëª¨ë¸")
print("=" * 80)
print()

# ============================================================================
# sklearn import ì‹œë„
# ============================================================================

try:
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
    from imblearn.over_sampling import SMOTE
    SKLEARN_AVAILABLE = True
    print("âœ… sklearnê³¼ imbalanced-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    SKLEARN_AVAILABLE = False
    print(f"âš ï¸ sklearn ë˜ëŠ” imbalanced-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("   pip install scikit-learn imbalanced-learn")
    sys.exit(1)

# ============================================================================
# ë°ì´í„° ìƒì„± (Week 1ê³¼ ë™ì¼)
# ============================================================================

def mean(data):
    return sum(data) / len(data) if data else 0

def normal_random(mean_val, std_val):
    u1 = random.random()
    u2 = random.random()
    z = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)
    return mean_val + z * std_val

def generate_data_scenario_a(n_samples=15000, accident_rate=0.359):
    """Scenario A: 4ê°œ ì´ë²¤íŠ¸ (ê³¼ì† í¬í•¨)"""
    random.seed(42)
    X = []
    y = []

    for i in range(n_samples):
        is_accident = 1 if random.random() < accident_rate else 0

        if is_accident:
            rapid_accel = max(0, int(normal_random(5.0, 2.0)))
            sudden_stop = max(0, int(normal_random(6.0, 2.5)))
            sharp_turn = max(0, int(normal_random(4.0, 2.0)))
            over_speed = max(0, int(normal_random(4.5, 2.0)))
        else:
            rapid_accel = max(0, int(normal_random(2.0, 1.5)))
            sudden_stop = max(0, int(normal_random(2.5, 1.5)))
            sharp_turn = max(0, int(normal_random(1.5, 1.0)))
            over_speed = max(0, int(normal_random(2.0, 1.5)))

        X.append([rapid_accel, sudden_stop, sharp_turn, over_speed])
        y.append(is_accident)

    return X, y

def generate_data_scenario_b(n_samples=15000, accident_rate=0.359):
    """Scenario B: 3ê°œ ì´ë²¤íŠ¸ (ê³¼ì† ì œì™¸)"""
    random.seed(42)
    X = []
    y = []

    for i in range(n_samples):
        is_accident = 1 if random.random() < accident_rate else 0

        if is_accident:
            rapid_accel = max(0, int(normal_random(5.0, 2.0)))
            sudden_stop = max(0, int(normal_random(6.0, 2.5)))
            sharp_turn = max(0, int(normal_random(4.0, 2.0)))
        else:
            rapid_accel = max(0, int(normal_random(2.0, 1.5)))
            sudden_stop = max(0, int(normal_random(2.5, 1.5)))
            sharp_turn = max(0, int(normal_random(1.5, 1.0)))

        X.append([rapid_accel, sudden_stop, sharp_turn])
        y.append(is_accident)

    return X, y

def train_test_split_custom(X, y, test_size=0.25):
    """Train/Test ë¶„í•  (sklearn ëŒ€ì‹  ì§ì ‘ êµ¬í˜„)"""
    random.seed(42)
    indices = list(range(len(X)))
    random.shuffle(indices)

    split_idx = int(len(X) * (1 - test_size))
    train_indices = indices[:split_idx]
    test_indices = indices[split_idx:]

    X_train = [X[i] for i in train_indices]
    y_train = [y[i] for i in train_indices]
    X_test = [X[i] for i in test_indices]
    y_test = [y[i] for i in test_indices]

    return X_train, X_test, y_train, y_test

# ============================================================================
# í‰ê°€ í•¨ìˆ˜
# ============================================================================

def find_optimal_threshold(y_true, y_proba, optimization='f1'):
    """ìµœì  Threshold íƒìƒ‰"""
    thresholds = [i * 0.01 for i in range(1, 100)]
    best_threshold = 0.5
    best_score = 0
    best_metrics = None

    for threshold in thresholds:
        y_pred = [1 if p >= threshold else 0 for p in y_proba]

        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)

        score = f1 if optimization == 'f1' else recall

        if score > best_score:
            best_score = score
            best_threshold = threshold
            best_metrics = {
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'threshold': threshold
            }

    return best_threshold, best_metrics

# ============================================================================
# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# ============================================================================

def run_ensemble_models(scenario_name, X_train, X_test, y_train, y_test):
    """Ensemble ëª¨ë¸ ì‹¤í–‰"""
    print(f"\n{'=' * 80}")
    print(f"ğŸ”¬ {scenario_name}")
    print(f"{'=' * 80}")

    print(f"\níŠ¹ì§• ê°œìˆ˜: {len(X_train[0])}ê°œ")
    print(f"Train: {len(X_train):,}ê°œ (ì‚¬ê³ ìœ¨: {sum(y_train)/len(y_train):.1%}), Test: {len(X_test):,}ê°œ (ì‚¬ê³ ìœ¨: {sum(y_test)/len(y_test):.1%})")

    results = {}

    # Step 1: SMOTE ì ìš© (Class Imbalance í•´ê²°)
    print(f"\n[Step 1: SMOTE ì ìš©]")
    print(f"  - ì›ë³¸ Train: {len(X_train):,}ê°œ (ì‚¬ê³ : {sum(y_train):,}ê°œ, ë¹„ì‚¬ê³ : {len(y_train)-sum(y_train):,}ê°œ)")

    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

    print(f"  - SMOTE í›„: {len(X_train_resampled):,}ê°œ (ì‚¬ê³ : {sum(y_train_resampled):,}ê°œ, ë¹„ì‚¬ê³ : {len(y_train_resampled)-sum(y_train_resampled):,}ê°œ)")
    print(f"  âœ… ì™„ë²½í•œ ê· í˜• ë‹¬ì„± (50:50)")

    # Step 2: ê°œë³„ ëª¨ë¸ í•™ìŠµ
    print(f"\n[Step 2: ê°œë³„ ëª¨ë¸ í•™ìŠµ]")

    models = {
        'LogisticRegression': LogisticRegression(
            max_iter=1000,
            class_weight='balanced',
            random_state=42
        ),
        'RandomForest': RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            min_samples_split=50,
            class_weight='balanced',
            random_state=42
        ),
        'GradientBoosting': GradientBoostingClassifier(
            n_estimators=200,
            learning_rate=0.05,
            max_depth=5,
            min_samples_split=50,
            random_state=42
        )
    }

    model_results = {}

    for model_name, model in models.items():
        print(f"\n  [{model_name}]")

        # í•™ìŠµ
        model.fit(X_train_resampled, y_train_resampled)

        # ì˜ˆì¸¡
        y_proba = model.predict_proba(X_test)[:, 1]

        # Threshold ìµœì í™”
        optimal_threshold, metrics = find_optimal_threshold(y_test, y_proba, optimization='f1')

        y_pred = [1 if p >= optimal_threshold else 0 for p in y_proba]

        # AUC ê³„ì‚°
        auc = roc_auc_score(y_test, y_proba)

        print(f"    ìµœì  Threshold: {optimal_threshold:.2f}")
        print(f"    Precision: {metrics['precision']:.1%}, Recall: {metrics['recall']:.1%}, F1: {metrics['f1']:.4f}, AUC: {auc:.4f}")

        model_results[model_name] = {
            'threshold': optimal_threshold,
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1': metrics['f1'],
            'auc': auc
        }

    results['individual_models'] = model_results

    # Step 3: Voting Ensemble
    print(f"\n[Step 3: Voting Ensemble (Soft Voting)]")

    voting_clf = VotingClassifier(
        estimators=[
            ('lr', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)),
            ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=50, class_weight='balanced', random_state=42)),
            ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, min_samples_split=50, random_state=42))
        ],
        voting='soft'
    )

    voting_clf.fit(X_train_resampled, y_train_resampled)
    y_proba_ensemble = voting_clf.predict_proba(X_test)[:, 1]

    # Threshold ìµœì í™”
    optimal_threshold_ensemble, metrics_ensemble = find_optimal_threshold(y_test, y_proba_ensemble, optimization='f1')

    y_pred_ensemble = [1 if p >= optimal_threshold_ensemble else 0 for p in y_proba_ensemble]

    # AUC ê³„ì‚°
    auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)

    print(f"  ìµœì  Threshold: {optimal_threshold_ensemble:.2f}")
    print(f"  Precision: {metrics_ensemble['precision']:.1%}, Recall: {metrics_ensemble['recall']:.1%}, F1: {metrics_ensemble['f1']:.4f}, AUC: {auc_ensemble:.4f}")

    results['ensemble'] = {
        'threshold': optimal_threshold_ensemble,
        'precision': metrics_ensemble['precision'],
        'recall': metrics_ensemble['recall'],
        'f1': metrics_ensemble['f1'],
        'auc': auc_ensemble
    }

    return results

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    print("\në°ì´í„° ìƒì„± ì¤‘...")

    # Scenario A (4ê°œ ì´ë²¤íŠ¸)
    X_a, y_a = generate_data_scenario_a(n_samples=15000, accident_rate=0.359)
    X_train_a, X_test_a, y_train_a, y_test_a = train_test_split_custom(X_a, y_a, test_size=0.25)
    results_a = run_ensemble_models("Scenario A (4ê°œ ì´ë²¤íŠ¸: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „, ê³¼ì†)", X_train_a, X_test_a, y_train_a, y_test_a)

    # Scenario B (3ê°œ ì´ë²¤íŠ¸)
    X_b, y_b = generate_data_scenario_b(n_samples=15000, accident_rate=0.359)
    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split_custom(X_b, y_b, test_size=0.25)
    results_b = run_ensemble_models("Scenario B (3ê°œ ì´ë²¤íŠ¸: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „)", X_train_b, X_test_b, y_train_b, y_test_b)

    # ìµœì¢… ë¹„êµ
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š Week 1 vs Week 2 ì„±ëŠ¥ ë¹„êµ")
    print(f"{'=' * 80}")

    # Week 1 ê²°ê³¼ ë¡œë“œ
    week1_file = os.path.join(os.path.dirname(__file__), 'phase4d_scenario_comparison.json')
    with open(week1_file, 'r', encoding='utf-8') as f:
        week1_results = json.load(f)

    print(f"\n{'ì‹œë‚˜ë¦¬ì˜¤':<20} {'Week':<10} {'ëª¨ë¸':<20} {'Precision':>12} {'Recall':>12} {'F1':>12} {'AUC':>12}")
    print("-" * 108)

    # Scenario A
    week1_a = week1_results['scenario_a']['phase4d']['metrics']
    ensemble_a = results_a['ensemble']

    print(f"{'Scenario A (4ê°œ)':<20} {'Week 1':<10} {'Class Weight + T':<20} {week1_a['precision']:>12.1%} {week1_a['recall']:>12.1%} {week1_a['f1']:>12.4f} {'N/A':>12}")
    print(f"{'Scenario A (4ê°œ)':<20} {'Week 2':<10} {'Voting Ensemble':<20} {ensemble_a['precision']:>12.1%} {ensemble_a['recall']:>12.1%} {ensemble_a['f1']:>12.4f} {ensemble_a['auc']:>12.4f}")

    f1_improvement_a = ensemble_a['f1'] - week1_a['f1']
    print(f"{'Scenario A (4ê°œ)':<20} {'ê°œì„ ':<10} {'':<20} {ensemble_a['precision'] - week1_a['precision']:>12.1%} {ensemble_a['recall'] - week1_a['recall']:>12.1%} {f1_improvement_a:>12.4f} {'':<12}")

    # Scenario B
    week1_b = week1_results['scenario_b']['phase4d']['metrics']
    ensemble_b = results_b['ensemble']

    print(f"{'Scenario B (3ê°œ)':<20} {'Week 1':<10} {'Class Weight + T':<20} {week1_b['precision']:>12.1%} {week1_b['recall']:>12.1%} {week1_b['f1']:>12.4f} {'N/A':>12}")
    print(f"{'Scenario B (3ê°œ)':<20} {'Week 2':<10} {'Voting Ensemble':<20} {ensemble_b['precision']:>12.1%} {ensemble_b['recall']:>12.1%} {ensemble_b['f1']:>12.4f} {ensemble_b['auc']:>12.4f}")

    f1_improvement_b = ensemble_b['f1'] - week1_b['f1']
    print(f"{'Scenario B (3ê°œ)':<20} {'ê°œì„ ':<10} {'':<20} {ensemble_b['precision'] - week1_b['precision']:>12.1%} {ensemble_b['recall'] - week1_b['recall']:>12.1%} {f1_improvement_b:>12.4f} {'':<12}")

    # ìµœì¢… ê¶Œì¥ì‚¬í•­
    print(f"\n{'=' * 80}")
    print(f"ğŸ’¡ ìµœì¢… ê¶Œì¥ì‚¬í•­")
    print(f"{'=' * 80}")

    best_f1 = max(ensemble_a['f1'], ensemble_b['f1'])
    best_scenario = "A" if ensemble_a['f1'] > ensemble_b['f1'] else "B"

    print(f"\nğŸ† ì¶”ì²œ: Scenario {best_scenario} + Week 2 Ensemble")
    if best_scenario == "A":
        print(f"   â†’ F1 Score: {ensemble_a['f1']:.4f} (Scenario B ëŒ€ë¹„ +{ensemble_a['f1'] - ensemble_b['f1']:.4f})")
        print(f"   â†’ AUC: {ensemble_a['auc']:.4f}")
        print(f"   â†’ Week 1 ëŒ€ë¹„ F1 ê°œì„ : {f1_improvement_a:+.4f}")
    else:
        print(f"   â†’ F1 Score: {ensemble_b['f1']:.4f} (Scenario A ëŒ€ë¹„ +{ensemble_b['f1'] - ensemble_a['f1']:.4f})")
        print(f"   â†’ AUC: {ensemble_b['auc']:.4f}")
        print(f"   â†’ Week 1 ëŒ€ë¹„ F1 ê°œì„ : {f1_improvement_b:+.4f}")

    # Week 2 íš¨ê³¼ ë¶„ì„
    print(f"\nğŸ“ˆ Week 2 Ensembleì˜ íš¨ê³¼:")
    if f1_improvement_a > 0 or f1_improvement_b > 0:
        print(f"  âœ… Scenario A: F1 {f1_improvement_a:+.4f} ({f1_improvement_a/week1_a['f1']*100:+.1f}%)")
        print(f"  âœ… Scenario B: F1 {f1_improvement_b:+.4f} ({f1_improvement_b/week1_b['f1']*100:+.1f}%)")
        print(f"  â†’ SMOTE + Ensembleì´ ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬")
    else:
        print(f"  âš ï¸ Scenario A: F1 {f1_improvement_a:+.4f} ({f1_improvement_a/week1_a['f1']*100:+.1f}%)")
        print(f"  âš ï¸ Scenario B: F1 {f1_improvement_b:+.4f} ({f1_improvement_b/week1_b['f1']*100:+.1f}%)")
        print(f"  â†’ Week 1ì˜ Class Weight + Threshold ìµœì í™”ê°€ ì´ë¯¸ ì¶©ë¶„íˆ íš¨ê³¼ì ")
        print(f"  â†’ Ensemble ë³µì¡ë„ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ ë¯¸ë¯¸ (Week 1 ìœ ì§€ ê¶Œì¥)")

    # ê²°ê³¼ ì €ì¥
    final_results = {
        'scenario_a': results_a,
        'scenario_b': results_b,
        'comparison': {
            'recommended_scenario': best_scenario,
            'f1_improvement_scenario_a': f1_improvement_a,
            'f1_improvement_scenario_b': f1_improvement_b,
            'week2_effective': f1_improvement_a > 0 or f1_improvement_b > 0
        }
    }

    output_file = os.path.join(os.path.dirname(__file__), 'phase4d_week2_ensemble.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False)

    print(f"\nê²°ê³¼ ì €ì¥: {output_file}")

    print(f"\n{'=' * 80}")
    print(f"âœ… Week 2 Ensemble ë¶„ì„ ì™„ë£Œ!")
    print(f"{'=' * 80}")

if __name__ == "__main__":
    main()
