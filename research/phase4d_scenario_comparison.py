#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 4-D: Scenario A vs B ì™„ì „ ë¹„êµ
====================================

Phase 4-Cì™€ Phase 4-Dë¥¼ Scenario A (4ê°œ ì´ë²¤íŠ¸)ì™€ Scenario B (3ê°œ ì´ë²¤íŠ¸)
ëª¨ë‘ì— ëŒ€í•´ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.

Scenario A: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „, ê³¼ì† (4ê°œ)
Scenario B: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „ (3ê°œ, ê³¼ì† ì œì™¸)

ì‘ì„±ì¼: 2025-10-10
"""

import os
import sys
import json
import random
import math

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

print("=" * 80)
print(" Phase 4-D: Scenario A vs B ì™„ì „ ë¹„êµ")
print("=" * 80)
print()

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def mean(data):
    return sum(data) / len(data) if data else 0

def normal_random(mean_val, std_val):
    u1 = random.random()
    u2 = random.random()
    z = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)
    return mean_val + z * std_val

# ============================================================================
# ëª¨ë¸ í´ë˜ìŠ¤
# ============================================================================

class LogisticRegression:
    """ê¸°ì¡´ Logistic Regression (Phase 4-C)"""
    def __init__(self, learning_rate=0.01, iterations=1000):
        self.lr = learning_rate
        self.iterations = iterations
        self.weights = None
        self.bias = None

    def sigmoid(self, z):
        return 1 / (1 + math.exp(-min(max(z, -500), 500)))

    def fit(self, X, y):
        n_samples, n_features = len(X), len(X[0])
        self.weights = [0.0] * n_features
        self.bias = 0.0

        for iteration in range(self.iterations):
            predictions = []
            for i in range(n_samples):
                z = sum(X[i][j] * self.weights[j] for j in range(n_features)) + self.bias
                predictions.append(self.sigmoid(z))

            dw = [0.0] * n_features
            db = 0.0
            for i in range(n_samples):
                error = predictions[i] - y[i]
                for j in range(n_features):
                    dw[j] += error * X[i][j]
                db += error

            for j in range(n_features):
                self.weights[j] -= self.lr * dw[j] / n_samples
            self.bias -= self.lr * db / n_samples

    def predict_proba(self, X):
        predictions = []
        for i in range(len(X)):
            z = sum(X[i][j] * self.weights[j] for j in range(len(self.weights))) + self.bias
            predictions.append(self.sigmoid(z))
        return predictions

    def predict(self, X, threshold=0.5):
        probas = self.predict_proba(X)
        return [1 if p >= threshold else 0 for p in probas]

class LogisticRegressionWithClassWeight:
    """Class Weight ì ìš© Logistic Regression (Phase 4-D)"""
    def __init__(self, learning_rate=0.01, iterations=1000, class_weight='balanced'):
        self.lr = learning_rate
        self.iterations = iterations
        self.class_weight = class_weight
        self.weights = None
        self.bias = None
        self.weight_positive = 1.0
        self.weight_negative = 1.0

    def sigmoid(self, z):
        return 1 / (1 + math.exp(-min(max(z, -500), 500)))

    def fit(self, X, y):
        n_samples, n_features = len(X), len(X[0])
        self.weights = [0.0] * n_features
        self.bias = 0.0

        if self.class_weight == 'balanced':
            n_positive = sum(y)
            n_negative = n_samples - n_positive
            self.weight_positive = n_samples / (2 * n_positive)
            self.weight_negative = n_samples / (2 * n_negative)

        for iteration in range(self.iterations):
            predictions = []
            for i in range(n_samples):
                z = sum(X[i][j] * self.weights[j] for j in range(n_features)) + self.bias
                predictions.append(self.sigmoid(z))

            dw = [0.0] * n_features
            db = 0.0
            for i in range(n_samples):
                error = predictions[i] - y[i]
                weight = self.weight_positive if y[i] == 1 else self.weight_negative
                for j in range(n_features):
                    dw[j] += weight * error * X[i][j]
                db += weight * error

            for j in range(n_features):
                self.weights[j] -= self.lr * dw[j] / n_samples
            self.bias -= self.lr * db / n_samples

    def predict_proba(self, X):
        predictions = []
        for i in range(len(X)):
            z = sum(X[i][j] * self.weights[j] for j in range(len(self.weights))) + self.bias
            predictions.append(self.sigmoid(z))
        return predictions

    def predict(self, X, threshold=0.5):
        probas = self.predict_proba(X)
        return [1 if p >= threshold else 0 for p in probas]

# ============================================================================
# í‰ê°€ í•¨ìˆ˜
# ============================================================================

def calculate_metrics(y_true, y_pred, y_proba):
    """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    tp = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 1)
    fp = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 1)
    tn = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 0)
    fn = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 0)

    accuracy = (tp + tn) / len(y_true) if len(y_true) > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    sorted_pairs = sorted(zip(y_proba, y_true), reverse=True)
    positives = sum(y_true)
    negatives = len(y_true) - positives

    if positives == 0 or negatives == 0:
        auc = 0.5
    else:
        true_positive = 0
        false_positive = 0
        auc_sum = 0.0
        prev_fpr = 0.0

        for prob, label in sorted_pairs:
            if label == 1:
                true_positive += 1
            else:
                false_positive += 1
                tpr = true_positive / positives
                fpr = false_positive / negatives
                auc_sum += (fpr - prev_fpr) * tpr
                prev_fpr = fpr

        auc = auc_sum

    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "auc": auc,
        "confusion_matrix": {"tp": tp, "fp": fp, "tn": tn, "fn": fn}
    }

def find_optimal_threshold(y_true, y_proba, optimization='f1'):
    """ìµœì  Threshold íƒìƒ‰"""
    thresholds = [i * 0.01 for i in range(1, 100)]
    best_threshold = 0.5
    best_score = 0
    best_metrics = None

    for threshold in thresholds:
        y_pred = [1 if p >= threshold else 0 for p in y_proba]

        tp = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 1)
        fp = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 1)
        tn = sum(1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 0)
        fn = sum(1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 0)

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        score = f1 if optimization == 'f1' else recall

        if score > best_score:
            best_score = score
            best_threshold = threshold
            best_metrics = {
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'confusion_matrix': {'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn}
            }

    return best_threshold, best_metrics

# ============================================================================
# ë°ì´í„° ìƒì„±
# ============================================================================

def generate_data_scenario_a(n_samples=15000, accident_rate=0.359):
    """Scenario A: 4ê°œ ì´ë²¤íŠ¸ (ê³¼ì† í¬í•¨)"""
    random.seed(42)
    X = []
    y = []

    for i in range(n_samples):
        is_accident = 1 if random.random() < accident_rate else 0

        if is_accident:
            rapid_accel = max(0, int(normal_random(5.0, 2.0)))
            sudden_stop = max(0, int(normal_random(6.0, 2.5)))
            sharp_turn = max(0, int(normal_random(4.0, 2.0)))
            over_speed = max(0, int(normal_random(4.5, 2.0)))
        else:
            rapid_accel = max(0, int(normal_random(2.0, 1.5)))
            sudden_stop = max(0, int(normal_random(2.5, 1.5)))
            sharp_turn = max(0, int(normal_random(1.5, 1.0)))
            over_speed = max(0, int(normal_random(2.0, 1.5)))

        X.append([rapid_accel, sudden_stop, sharp_turn, over_speed])
        y.append(is_accident)

    return X, y

def generate_data_scenario_b(n_samples=15000, accident_rate=0.359):
    """Scenario B: 3ê°œ ì´ë²¤íŠ¸ (ê³¼ì† ì œì™¸)"""
    random.seed(42)
    X = []
    y = []

    for i in range(n_samples):
        is_accident = 1 if random.random() < accident_rate else 0

        if is_accident:
            rapid_accel = max(0, int(normal_random(5.0, 2.0)))
            sudden_stop = max(0, int(normal_random(6.0, 2.5)))
            sharp_turn = max(0, int(normal_random(4.0, 2.0)))
        else:
            rapid_accel = max(0, int(normal_random(2.0, 1.5)))
            sudden_stop = max(0, int(normal_random(2.5, 1.5)))
            sharp_turn = max(0, int(normal_random(1.5, 1.0)))

        X.append([rapid_accel, sudden_stop, sharp_turn])
        y.append(is_accident)

    return X, y

def train_test_split(X, y, test_size=0.25):
    """Train/Test ë¶„í• """
    random.seed(42)
    indices = list(range(len(X)))
    random.shuffle(indices)

    split_idx = int(len(X) * (1 - test_size))
    train_indices = indices[:split_idx]
    test_indices = indices[split_idx:]

    X_train = [X[i] for i in train_indices]
    y_train = [y[i] for i in train_indices]
    X_test = [X[i] for i in test_indices]
    y_test = [y[i] for i in test_indices]

    return X_train, X_test, y_train, y_test

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def run_scenario(scenario_name, X, y):
    """ê° ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    print(f"\n{'=' * 80}")
    print(f"ğŸ”¬ {scenario_name}")
    print(f"{'=' * 80}")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

    print(f"\níŠ¹ì§• ê°œìˆ˜: {len(X[0])}ê°œ")
    print(f"Train: {len(X_train):,}ê°œ, Test: {len(X_test):,}ê°œ")

    results = {}

    # Phase 4-C
    print(f"\n[Phase 4-C: Baseline]")
    model_4c = LogisticRegression(learning_rate=0.01, iterations=500)
    model_4c.fit(X_train, y_train)

    y_proba_4c = model_4c.predict_proba(X_test)
    y_pred_4c = model_4c.predict(X_test, threshold=0.5)
    metrics_4c = calculate_metrics(y_test, y_pred_4c, y_proba_4c)

    print(f"  Precision: {metrics_4c['precision']:.1%}, Recall: {metrics_4c['recall']:.1%}, F1: {metrics_4c['f1']:.4f}, AUC: {metrics_4c['auc']:.4f}")

    results['phase4c'] = {
        'threshold': 0.5,
        'metrics': metrics_4c
    }

    # Phase 4-D: Class Weight + Threshold ìµœì í™”
    print(f"\n[Phase 4-D: Class Weight + Threshold Optimization]")
    model_4d = LogisticRegressionWithClassWeight(
        learning_rate=0.01,
        iterations=500,
        class_weight='balanced'
    )
    model_4d.fit(X_train, y_train)

    y_proba_4d = model_4d.predict_proba(X_test)

    # F1 ìµœëŒ€í™” Threshold íƒìƒ‰
    optimal_threshold, metrics_4d = find_optimal_threshold(y_test, y_proba_4d, optimization='f1')

    print(f"  ìµœì  Threshold: {optimal_threshold:.2f}")
    print(f"  Precision: {metrics_4d['precision']:.1%}, Recall: {metrics_4d['recall']:.1%}, F1: {metrics_4d['f1']:.4f}")

    results['phase4d'] = {
        'threshold': optimal_threshold,
        'metrics': metrics_4d
    }

    # ê°œì„  ë¶„ì„
    print(f"\n[ê°œì„  ë¶„ì„]")
    recall_change = metrics_4d['recall'] - metrics_4c['recall']
    precision_change = metrics_4d['precision'] - metrics_4c['precision']
    f1_change = metrics_4d['f1'] - metrics_4c['f1']

    print(f"  Recall:    {metrics_4c['recall']:.1%} â†’ {metrics_4d['recall']:.1%} ({recall_change:+.1%})")
    print(f"  Precision: {metrics_4c['precision']:.1%} â†’ {metrics_4d['precision']:.1%} ({precision_change:+.1%})")
    print(f"  F1 Score:  {metrics_4c['f1']:.4f} â†’ {metrics_4d['f1']:.4f} ({f1_change:+.4f}, {metrics_4d['f1']/metrics_4c['f1']:.2f}ë°°)")

    results['improvements'] = {
        'recall_change': recall_change,
        'precision_change': precision_change,
        'f1_change': f1_change,
        'f1_multiplier': metrics_4d['f1'] / metrics_4c['f1'] if metrics_4c['f1'] > 0 else 0
    }

    return results

def main():
    print("\në°ì´í„° ìƒì„± ì¤‘...")

    # Scenario A (4ê°œ ì´ë²¤íŠ¸)
    X_a, y_a = generate_data_scenario_a(n_samples=15000, accident_rate=0.359)
    results_a = run_scenario("Scenario A (4ê°œ ì´ë²¤íŠ¸: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „, ê³¼ì†)", X_a, y_a)

    # Scenario B (3ê°œ ì´ë²¤íŠ¸)
    X_b, y_b = generate_data_scenario_b(n_samples=15000, accident_rate=0.359)
    results_b = run_scenario("Scenario B (3ê°œ ì´ë²¤íŠ¸: ê¸‰ê°€ì†, ê¸‰ì •ê±°, ê¸‰íšŒì „)", X_b, y_b)

    # ìµœì¢… ë¹„êµ
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š Scenario A vs B ìµœì¢… ë¹„êµ")
    print(f"{'=' * 80}")

    print(f"\n{'ì‹œë‚˜ë¦¬ì˜¤':<20} {'Phase':<10} {'Precision':>12} {'Recall':>12} {'F1':>12} {'Threshold':>12}")
    print("-" * 88)

    # Scenario A
    metrics_a_4c = results_a['phase4c']['metrics']
    metrics_a_4d = results_a['phase4d']['metrics']
    print(f"{'Scenario A (4ê°œ)':<20} {'Phase 4-C':<10} {metrics_a_4c['precision']:>12.1%} {metrics_a_4c['recall']:>12.1%} {metrics_a_4c['f1']:>12.4f} {results_a['phase4c']['threshold']:>12.2f}")
    print(f"{'Scenario A (4ê°œ)':<20} {'Phase 4-D':<10} {metrics_a_4d['precision']:>12.1%} {metrics_a_4d['recall']:>12.1%} {metrics_a_4d['f1']:>12.4f} {results_a['phase4d']['threshold']:>12.2f}")

    # Scenario B
    metrics_b_4c = results_b['phase4c']['metrics']
    metrics_b_4d = results_b['phase4d']['metrics']
    print(f"{'Scenario B (3ê°œ)':<20} {'Phase 4-C':<10} {metrics_b_4c['precision']:>12.1%} {metrics_b_4c['recall']:>12.1%} {metrics_b_4c['f1']:>12.4f} {results_b['phase4c']['threshold']:>12.2f}")
    print(f"{'Scenario B (3ê°œ)':<20} {'Phase 4-D':<10} {metrics_b_4d['precision']:>12.1%} {metrics_b_4d['recall']:>12.1%} {metrics_b_4d['f1']:>12.4f} {results_b['phase4d']['threshold']:>12.2f}")

    # ê¶Œì¥ì‚¬í•­
    print(f"\n{'=' * 80}")
    print(f"ğŸ’¡ ìµœì¢… ê¶Œì¥ì‚¬í•­")
    print(f"{'=' * 80}")

    # F1 Score ë¹„êµ
    best_scenario = "A" if metrics_a_4d['f1'] > metrics_b_4d['f1'] else "B"
    best_f1 = max(metrics_a_4d['f1'], metrics_b_4d['f1'])

    print(f"\nğŸ† ì¶”ì²œ: Scenario {best_scenario} + Phase 4-D")
    if best_scenario == "A":
        print(f"   â†’ F1 Score: {metrics_a_4d['f1']:.4f} (Scenario B ëŒ€ë¹„ +{metrics_a_4d['f1'] - metrics_b_4d['f1']:.4f})")
        print(f"   â†’ 4ê°œ ì´ë²¤íŠ¸ (ê³¼ì† í¬í•¨)")
    else:
        print(f"   â†’ F1 Score: {metrics_b_4d['f1']:.4f} (Scenario A ëŒ€ë¹„ +{metrics_b_4d['f1'] - metrics_a_4d['f1']:.4f})")
        print(f"   â†’ 3ê°œ ì´ë²¤íŠ¸ (ê³¼ì† ì œì™¸)")

    print(f"\nì´ìœ :")
    if best_scenario == "A":
        print(f"  1. âœ… F1 Score ìµœê³  ({metrics_a_4d['f1']:.4f})")
        print(f"  2. âœ… Precision {metrics_a_4d['precision']:.1%}, Recall {metrics_a_4d['recall']:.1%}")
        print(f"  3. âš ï¸ ê³¼ì† ì´ë²¤íŠ¸ ì¶”ê°€ êµ¬í˜„ í•„ìš” (GPS, ì œí•œì†ë„ ì •ë³´)")
    else:
        print(f"  1. âœ… F1 Score ìš°ìˆ˜ ({metrics_b_4d['f1']:.4f})")
        print(f"  2. âœ… êµ¬í˜„ ë‹¨ìˆœ (3ê°œ ì´ë²¤íŠ¸ë§Œ)")
        print(f"  3. âœ… GPS ì˜ì¡´ì„± ì—†ìŒ")

    # ê²°ê³¼ ì €ì¥
    final_results = {
        'scenario_a': results_a,
        'scenario_b': results_b,
        'comparison': {
            'recommended_scenario': best_scenario,
            'f1_difference': abs(metrics_a_4d['f1'] - metrics_b_4d['f1']),
            'scenario_a_better': metrics_a_4d['f1'] > metrics_b_4d['f1']
        }
    }

    output_file = os.path.join(os.path.dirname(__file__), 'phase4d_scenario_comparison.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False)

    print(f"\nê²°ê³¼ ì €ì¥: {output_file}")

    print(f"\n{'=' * 80}")
    print(f"âœ… Scenario A vs B ë¹„êµ ì™„ë£Œ!")
    print(f"{'=' * 80}")

if __name__ == "__main__":
    main()
