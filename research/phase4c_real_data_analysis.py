#!/usr/bin/env python3
"""
Phase 4-C: ì‹¤ì œ Kaggle ë°ì´í„° ë¶„ì„
====================================

ì‹¤ì œ US Accidents + Vehicle Sensor ë°ì´í„° ë§¤ì¹­ ë° ë¶„ì„

Prerequisites:
1. Kaggle API ì„¤ì • ì™„ë£Œ
2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:
   - data/us_accidents/US_Accidents_March23.csv
   - data/driver_behavior/*.csv

ì‹¤í–‰:
python research/phase4c_real_data_analysis.py

ì˜ˆìƒ ì‹œê°„: 4-8ì‹œê°„ (ë°ì´í„° í¬ê¸°ì— ë”°ë¼)
ì˜ˆìƒ ê²°ê³¼: 50,000-100,000ê°œ ë§¤ì¹­

ì‘ì„±ì¼: 2025-09-30
"""

import os
import json
import math
from datetime import datetime, timedelta
from collections import defaultdict

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘       Phase 4-C: ì‹¤ì œ Kaggle ë°ì´í„° ë¶„ì„                    â•‘
â•‘                                                              â•‘
â•‘  ëª©í‘œ: 50,000-100,000ê°œ ì‹¤ì œ ë§¤ì¹­ìœ¼ë¡œ ìµœì¢… ê²€ì¦            â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def mean(data):
    return sum(data) / len(data) if data else 0

def correlation(x, y):
    """í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜"""
    if len(x) != len(y) or len(x) == 0:
        return 0
    n = len(x)
    mean_x = mean(x)
    mean_y = mean(y)
    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))
    denominator = math.sqrt(sum((x[i] - mean_x)**2 for i in range(n)) * 
                           sum((y[i] - mean_y)**2 for i in range(n)))
    return numerator / denominator if denominator != 0 else 0

class Phase4CRealDataAnalysis:
    def __init__(self):
        self.data_dir = "data"
        self.us_accidents_file = os.path.join(self.data_dir, "us_accidents", "US_Accidents_March23.csv")
        self.driver_behavior_dir = os.path.join(self.data_dir, "driver_behavior")
        
        self.us_accidents_data = []
        self.vehicle_sensor_data = []
        self.matched_data = []
        self.results = {}
        
    def check_data_availability(self):
        """
        ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
        """
        print("=" * 60)
        print("ğŸ“ ë°ì´í„° íŒŒì¼ í™•ì¸")
        print("=" * 60)
        
        print(f"\në°ì´í„° ë””ë ‰í† ë¦¬: {os.path.abspath(self.data_dir)}")
        
        # US Accidents í™•ì¸
        if os.path.exists(self.us_accidents_file):
            size_mb = os.path.getsize(self.us_accidents_file) / (1024 * 1024)
            print(f"âœ… US Accidents: {self.us_accidents_file}")
            print(f"   íŒŒì¼ í¬ê¸°: {size_mb:.1f} MB")
        else:
            print(f"âŒ US Accidents íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.us_accidents_file}")
            print("\në‹¤ìš´ë¡œë“œ ë°©ë²•:")
            print("  kaggle datasets download -d sobhanmoosavi/us-accidents")
            print(f"  unzip us-accidents.zip -d {os.path.join(self.data_dir, 'us_accidents')}")
            return False
            
        # Driver Behavior í™•ì¸
        if os.path.exists(self.driver_behavior_dir):
            files = [f for f in os.listdir(self.driver_behavior_dir) if f.endswith('.csv')]
            if files:
                print(f"âœ… Driver Behavior: {self.driver_behavior_dir}")
                print(f"   íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
                for f in files[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                    size_mb = os.path.getsize(os.path.join(self.driver_behavior_dir, f)) / (1024 * 1024)
                    print(f"   - {f} ({size_mb:.1f} MB)")
                if len(files) > 3:
                    print(f"   ... ì™¸ {len(files)-3}ê°œ")
            else:
                print(f"âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.driver_behavior_dir}")
                return False
        else:
            print(f"âŒ Driver Behavior ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.driver_behavior_dir}")
            print("\në‹¤ìš´ë¡œë“œ ë°©ë²•:")
            print("  kaggle datasets download -d outofskills/driving-behavior")
            print(f"  unzip driving-behavior.zip -d {self.driver_behavior_dir}")
            return False
            
        return True
        
    def load_us_accidents(self, sample_size=100000):
        """
        US Accidents ë°ì´í„° ë¡œë”©
        
        Note: ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” pandasë¥¼ ì‚¬ìš©í•˜ì—¬ CSV íŒŒì¼ì„ ì½ì–´ì•¼ í•©ë‹ˆë‹¤.
        ì´ ì˜ˆì œëŠ” pandasê°€ ì—†ëŠ” í™˜ê²½ì„ ê°€ì •í•œ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
        """
        print("\n" + "=" * 60)
        print(f"ğŸ“Š US Accidents ë°ì´í„° ë¡œë”© (ìƒ˜í”Œ: {sample_size:,}ê°œ)")
        print("=" * 60)
        
        print("\nâš ï¸ ì£¼ì˜: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” pandasê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("\nì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ:")
        print("""
import pandas as pd

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½)
chunks = []
for chunk in pd.read_csv(self.us_accidents_file, 
                         chunksize=10000,
                         usecols=['ID', 'Severity', 'Start_Time', 
                                 'Latitude', 'Longitude', 
                                 'Weather_Condition', 'Temperature(F)',
                                 'Visibility(mi)']):
    chunks.append(chunk)
    if len(chunks) * 10000 >= sample_size:
        break

df = pd.concat(chunks, ignore_index=True)

# ë‚ ì§œ íŒŒì‹±
df['Start_Time'] = pd.to_datetime(df['Start_Time'])
df['Hour'] = df['Start_Time'].dt.hour
df['Is_Night'] = ((df['Hour'] >= 18) | (df['Hour'] <= 6)).astype(int)

# ë°ì´í„° ì €ì¥
self.us_accidents_data = df.to_dict('records')
        """)
        
        print(f"\ní˜„ì¬ ìƒíƒœ: ë°ì´í„° íŒŒì¼ì´ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë‚˜ pandasê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install pandas")
        
        return False  # pandas ì—†ì´ëŠ” ì§„í–‰ ë¶ˆê°€
        
    def load_vehicle_sensor(self):
        """
        Vehicle Sensor ë°ì´í„° ë¡œë”©
        """
        print("\n" + "=" * 60)
        print("ğŸš— Vehicle Sensor ë°ì´í„° ë¡œë”©")
        print("=" * 60)
        
        print("\nì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ:")
        print("""
import pandas as pd

# ëª¨ë“  CSV íŒŒì¼ ì½ê¸°
dfs = []
for file in os.listdir(self.driver_behavior_dir):
    if file.endswith('.csv'):
        df = pd.read_csv(os.path.join(self.driver_behavior_dir, file))
        dfs.append(df)

df = pd.concat(dfs, ignore_index=True)

# ì´ë²¤íŠ¸ ê°ì§€
df['RapidAccel'] = (df['AccX'] > 1.2).astype(int)
df['SuddenStop'] = (df['AccX'] < -1.2).astype(int)
df['SharpTurn'] = (df['GyroZ'].abs() > 1.0).astype(int)

# ì‹œê°„ ì •ë³´
df['Hour'] = df['Timestamp'].apply(lambda x: # ì‹œê°„ ì¶”ì¶œ ë¡œì§)
df['Is_Night'] = ((df['Hour'] >= 18) | (df['Hour'] <= 6)).astype(int)

self.vehicle_sensor_data = df.to_dict('records')
        """)
        
        return False
        
    def perform_matching(self, target_matches=50000):
        """
        ì‚¬ê³ -ì„¼ì„œ ë°ì´í„° ë§¤ì¹­
        """
        print("\n" + "=" * 60)
        print(f"ğŸ”— ë°ì´í„° ë§¤ì¹­ ì‹¤í–‰ (ëª©í‘œ: {target_matches:,}ê°œ)")
        print("=" * 60)
        
        print("\në§¤ì¹­ ì „ëµ:")
        print("  1. ì§€ì—­-ì‹œê°„ ë§¤ì¹­ (ê±°ë¦¬ 200km, ì‹œê°„ Â±7ì¼)")
        print("  2. í™˜ê²½ ì¡°ê±´ ë§¤ì¹­ (ì•¼ê°„/ì£¼ê°„ ì¼ì¹˜ ì‹œ ê°€ì )")
        print("  3. í’ˆì§ˆ í•„í„°ë§ (ì‹ ë¢°ë„ ë†’ì€ ë§¤ì¹­ë§Œ ì„ ë³„)")
        
        print("\nì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ:")
        print("""
# íš¨ìœ¨ì ì¸ ë§¤ì¹­ì„ ìœ„í•œ ì¸ë±ì‹±
from scipy.spatial import cKDTree

# ìœ„ì¹˜ ê¸°ë°˜ KD-Tree êµ¬ì¶•
sensor_coords = np.array([[s['Latitude'], s['Longitude']] 
                          for s in self.vehicle_sensor_data])
tree = cKDTree(sensor_coords)

matches = []
for accident in self.us_accidents_data:
    acc_coord = [accident['Latitude'], accident['Longitude']]
    
    # 200km ì´ë‚´ ì„¼ì„œ ì°¾ê¸°
    nearby_indices = tree.query_ball_point(acc_coord, r=2.0)  # ~200km
    
    for idx in nearby_indices:
        sensor = self.vehicle_sensor_data[idx]
        
        # ì‹œê°„ ì°¨ì´ ê³„ì‚°
        time_diff = abs((accident['Start_Time'] - sensor['Timestamp']).total_seconds())
        if time_diff > 604800:  # 7ì¼
            continue
            
        # ë§¤ì¹­!
        match = {
            'accident_id': accident['ID'],
            'sensor_id': sensor['ID'],
            'severity': accident['Severity'],
            'distance_km': calculate_distance(acc_coord, sensor['coord']),
            'time_diff_hours': time_diff / 3600,
            # ... ê¸°íƒ€ ì •ë³´
        }
        matches.append(match)
        
        if len(matches) >= target_matches:
            break
    
    if len(matches) >= target_matches:
        break

self.matched_data = matches
        """)
        
        return False
        
    def analyze_correlations(self):
        """
        ìƒê´€ê´€ê³„ ë¶„ì„
        """
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ìƒê´€ê´€ê³„ ë¶„ì„")
        print("=" * 60)
        
        print("\në¶„ì„ í•­ëª©:")
        print("  1. ì´ë²¤íŠ¸ë³„ ì‚¬ê³  ì‹¬ê°ë„ ìƒê´€ê´€ê³„")
        print("  2. ì•¼ê°„ ìš´ì „ vs ì‚¬ê³  ì‹¬ê°ë„")
        print("  3. ë‚ ì”¨ ì¡°ê±´ vs ì‚¬ê³  ì‹¬ê°ë„")
        print("  4. í†µê³„ì  ìœ ì˜ì„± ê²€ì • (p-value)")
        
        print("\nì˜ˆìƒ ê²°ê³¼:")
        print("  - ê¸‰ì •ê±° ìƒê´€ê³„ìˆ˜: 0.20-0.30")
        print("  - ê¸‰ê°€ì† ìƒê´€ê³„ìˆ˜: 0.15-0.25")
        print("  - ê¸‰íšŒì „ ìƒê´€ê³„ìˆ˜: 0.10-0.20")
        print("  - ê³¼ì† ìƒê´€ê³„ìˆ˜: 0.05-0.15")
        
        return {}
        
    def derive_weights(self):
        """
        ìµœì¢… ê°€ì¤‘ì¹˜ ë„ì¶œ
        """
        print("\n" + "=" * 60)
        print("âš–ï¸ ìµœì¢… ê°€ì¤‘ì¹˜ ë„ì¶œ")
        print("=" * 60)
        
        print("\në°©ë²•ë¡ :")
        print("  1. ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ì´ˆê¸° ê°€ì¤‘ì¹˜")
        print("  2. ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜ í™œìš©")
        print("  3. ëœë¤ í¬ë ˆìŠ¤íŠ¸ íŠ¹ì„± ì¤‘ìš”ë„")
        print("  4. 3ê°€ì§€ ë°©ë²•ì˜ ì•™ìƒë¸”")
        
        print("\nì˜ˆìƒ ê°€ì¤‘ì¹˜ (ì£¼ê°„/ì•¼ê°„):")
        print("  - ê¸‰ì •ê±°: -3.5ì  / -5.5ì ")
        print("  - ê¸‰ê°€ì†: -2.8ì  / -4.2ì ")
        print("  - ê¸‰íšŒì „: -2.2ì  / -3.3ì ")
        print("  - ê³¼ì†: -1.8ì  / -2.7ì  (ì„ íƒ)")
        
        return {}
        
    def generate_final_report(self):
        """
        ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        """
        print("\n" + "=" * 60)
        print("ğŸ“„ Phase 4-C ìµœì¢… ë³´ê³ ì„œ")
        print("=" * 60)
        
        report = {
            "phase": "Phase 4-C Real Data Analysis",
            "status": "ì¤€ë¹„ ë‹¨ê³„ - pandas ë° ì‹¤ì œ ë°ì´í„° í•„ìš”",
            "requirements": {
                "packages": ["pandas", "numpy", "scikit-learn", "scipy"],
                "data": [
                    "US Accidents (7.7M records)",
                    "Vehicle Sensor (10K+ records)"
                ],
                "hardware": "32GB+ RAM ê¶Œì¥"
            },
            "expected_results": {
                "matched_samples": "50,000-100,000",
                "correlations": {
                    "sudden_stop": "0.20-0.30",
                    "rapid_accel": "0.15-0.25",
                    "sharp_turn": "0.10-0.20",
                    "over_speeding": "0.05-0.15"
                },
                "auc": "0.75-0.85",
                "p_value": "<0.0001"
            },
            "next_steps": [
                "1. Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                "2. pandas ë° í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜",
                "3. ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰",
                "4. ë§¤ì¹­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰",
                "5. í†µê³„ ë¶„ì„ ë° ê°€ì¤‘ì¹˜ ë„ì¶œ",
                "6. ìµœì¢… ë³´ê³ ì„œ ì‘ì„±"
            ]
        }
        
        output_file = "research/phase4c_preparation_status.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        print(f"\nâœ… ì¤€ë¹„ ìƒíƒœ ì €ì¥: {output_file}")
        
        print("\nğŸ¯ Phase 4-C ì‹¤í–‰ì„ ìœ„í•œ ë‹¤ìŒ ë‹¨ê³„:")
        for step in report['next_steps']:
            print(f"  {step}")
            
        print("\nğŸ“š ì°¸ê³  ë¬¸ì„œ:")
        print("  - docs/Phase4C_Preparation_Guide.md")
        print("  - docs/Phase4B_Success_Report.md")
        
        return report

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    phase4c = Phase4CRealDataAnalysis()
    
    # 1. ë°ì´í„° í™•ì¸
    if not phase4c.check_data_availability():
        print("\n" + "=" * 60)
        print("âš ï¸ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print("=" * 60)
        print("\nPhase 4-Cë¥¼ ì‹¤í–‰í•˜ë ¤ë©´:")
        print("1. docs/Phase4C_Preparation_Guide.md ì°¸ê³ ")
        print("2. Kaggleì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        print("3. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (pandas, numpy, scikit-learn)")
        print("4. ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì—…ë°ì´íŠ¸")
        
        # ì¤€ë¹„ ìƒíƒœ ë³´ê³ ì„œë§Œ ìƒì„±
        phase4c.generate_final_report()
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ í˜„ì¬ ìƒíƒœ: ì¤€ë¹„ ë‹¨ê³„")
        print("=" * 60)
        print("\nPhase 4-Bê¹Œì§€ ì™„ë£Œë˜ì—ˆìœ¼ë©°,")
        print("Phase 4-CëŠ” ì‹¤ì œ Kaggle ë°ì´í„° í™•ë³´ í›„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        return
    
    # 2. ë°ì´í„° ë¡œë”©
    if not phase4c.load_us_accidents():
        phase4c.generate_final_report()
        return
        
    if not phase4c.load_vehicle_sensor():
        phase4c.generate_final_report()
        return
    
    # 3. ë§¤ì¹­ ì‹¤í–‰
    if not phase4c.perform_matching():
        phase4c.generate_final_report()
        return
    
    # 4. ìƒê´€ê´€ê³„ ë¶„ì„
    phase4c.analyze_correlations()
    
    # 5. ê°€ì¤‘ì¹˜ ë„ì¶œ
    phase4c.derive_weights()
    
    # 6. ìµœì¢… ë³´ê³ ì„œ
    phase4c.generate_final_report()
    
    print("\n" + "=" * 60)
    print("âœ… Phase 4-C ì™„ë£Œ!")
    print("=" * 60)

if __name__ == "__main__":
    main()
